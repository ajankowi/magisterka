{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e139a52d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e139a52d",
        "outputId": "1495eeec-25fe-49ef-c8d0-fb161e24abd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "OG3xPR0PjOoi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG3xPR0PjOoi",
        "outputId": "a53b83d2-e1cf-4320-d52f-bf05b27b94d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e091328c",
      "metadata": {
        "id": "e091328c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch==2.1.0+cu118 torchvision==0.16.0+cu118 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "\n",
        "#!pip install jaxlib==0.4.0\n",
        "#!pip install torch==1.11.0 torchvision==0.12.0"
      ],
      "metadata": {
        "id": "7DXgdZgS-AKX",
        "outputId": "aca433ec-f7e2-4905-8c3b-5889c73e8aba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7DXgdZgS-AKX",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==2.1.1+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.1.1%2Bcu121-cp310-cp310-linux_x86_64.whl (2200.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 GB\u001b[0m \u001b[31m477.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.1+cu121\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.16.1%2Bcu121-cp310-cp310-linux_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1+cu121) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1+cu121) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1+cu121) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1+cu121) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1+cu121) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1+cu121) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1+cu121) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.1+cu121) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.1+cu121) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.16.1+cu121) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.1+cu121) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.1+cu121) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.1+cu121) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.1+cu121) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.16.1+cu121) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.1+cu121) (1.3.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0+cu118\n",
            "    Uninstalling torch-2.1.0+cu118:\n",
            "      Successfully uninstalled torch-2.1.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0+cu118\n",
            "    Uninstalling torchvision-0.16.0+cu118:\n",
            "      Successfully uninstalled torchvision-0.16.0+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.1.1+cu121 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.1+cu121 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.1+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.1+cu121 torchvision-0.16.1+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVlabs/stylegan3.git\n",
        "!pip install ninja"
      ],
      "metadata": {
        "id": "7Jmuj3AtfFmh",
        "outputId": "68fec359-81ac-4b1f-9798-0a628686bb39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "7Jmuj3AtfFmh",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 212 (delta 0), reused 1 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (212/212), 4.17 MiB | 16.57 MiB/s, done.\n",
            "Resolving deltas: 100% (98/98), done.\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.11.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1FpIT6hKjVnu",
      "metadata": {
        "id": "1FpIT6hKjVnu"
      },
      "outputs": [],
      "source": [
        "MNIST_zip = '/content/drive/MyDrive/MNIST/four_img.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/stylegan3"
      ],
      "metadata": {
        "id": "J_o5QxFHfgyj",
        "outputId": "c67c1653-8bce-45f5-dbec-e8b4f6b90a70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "J_o5QxFHfgyj",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "avg_spectra.py\t dnnlib      environment.yml  gui_utils    metrics\ttraining       viz\n",
            "calc_metrics.py  Dockerfile  gen_images.py    legacy.py    README.md\ttrain.py\n",
            "dataset_tool.py  docs\t     gen_video.py     LICENSE.txt  torch_utils\tvisualizer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"/content/stylegan3\")\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display\n",
        "import torch\n",
        "import dnnlib\n",
        "import legacy"
      ],
      "metadata": {
        "id": "XEInyVUJfg3B"
      },
      "id": "XEInyVUJfg3B",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "rUQpo8kLfg9C"
      },
      "id": "rUQpo8kLfg9C",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Using device: {device}\")\n",
        "\n",
        "num_of_gpus = torch.cuda.device_count()\n",
        "print(num_of_gpus)\n"
      ],
      "metadata": {
        "id": "-LqvcmnffhBS",
        "outputId": "412366a9-4e98-4f25-efeb-b938d848747b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "-LqvcmnffhBS",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/StyleGan3_gray_scale/dataset_tool.py --source=/content/drive/MyDrive/MNIST/four_img.zip --dest=/content/drive/MyDrive/MNIST/four_new_img_24_11.zip --transform=center-crop --resolution=16x16\n"
      ],
      "metadata": {
        "id": "Tk2L67PzfhFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00bb4448-674e-492e-9fa4-336736418484"
      },
      "id": "Tk2L67PzfhFO",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 5842/5842 [00:06<00:00, 970.69it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/StyleGan3_gray_scale/train.py --outdir=/content/drive/MyDrive/MNIST/wyniczek_2 --data=/content/drive/MyDrive/MNIST/four_new_img_24_11.zip  --gpus=1 --cfg=stylegan3-r --batch=16 --gamma=3.2768 --kimg=1000"
      ],
      "metadata": {
        "id": "JFWFfWigfhI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef302d7-31c0-4462-dbae-9f8fd0212557"
      },
      "id": "JFWFfWigfhI8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 65536,\n",
            "    \"channel_max\": 1024,\n",
            "    \"magnitude_ema_beta\": 0.9994456359721023,\n",
            "    \"conv_kernel\": 1,\n",
            "    \"use_radial_filters\": true\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 3.2768,\n",
            "    \"blur_init_sigma\": 10,\n",
            "    \"blur_fade_kimg\": 100.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"/content/drive/MyDrive/MNIST/four_new_img_24_11.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 5842,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 16,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 1000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"/content/drive/MyDrive/MNIST/wyniczek_2/00000-stylegan3-r-four_new_img_24_11-gpus1-batch16-gamma3.2768\"\n",
            "}\n",
            "\n",
            "Output directory:    /content/drive/MyDrive/MNIST/wyniczek_2/00000-stylegan3-r-four_new_img_24_11-gpus1-batch16-gamma3.2768\n",
            "Number of GPUs:      1\n",
            "Batch size:          16 images\n",
            "Training duration:   1000 kimg\n",
            "Dataset path:        /content/drive/MyDrive/MNIST/four_new_img_24_11.zip\n",
            "Dataset size:        5842 images\n",
            "Dataset resolution:  16\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  5842\n",
            "Image shape: [1, 16, 16]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape        Datatype\n",
            "---                           ---         ---      ---                 ---     \n",
            "mapping.fc0                   262656      -        [16, 512]           float32 \n",
            "mapping.fc1                   262656      -        [16, 512]           float32 \n",
            "mapping                       -           512      [16, 16, 512]       float32 \n",
            "synthesis.input.affine        2052        -        [16, 4]             float32 \n",
            "synthesis.input               1048576     3081     [16, 1024, 36, 36]  float32 \n",
            "synthesis.L0_36_1024.affine   525312      -        [16, 1024]          float32 \n",
            "synthesis.L0_36_1024          1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L1_36_1024.affine   525312      -        [16, 1024]          float32 \n",
            "synthesis.L1_36_1024          1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L2_36_1024.affine   525312      -        [16, 1024]          float32 \n",
            "synthesis.L2_36_1024          1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L3_36_1024.affine   525312      -        [16, 1024]          float32 \n",
            "synthesis.L3_36_1024          1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L4_36_1024.affine   525312      -        [16, 1024]          float32 \n",
            "synthesis.L4_36_1024          1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L5_36_1024.affine   525312      -        [16, 1024]          float32 \n",
            "synthesis.L5_36_1024          1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L6_36_1024.affine   525312      -        [16, 1024]          float32 \n",
            "synthesis.L6_36_1024          1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L7_36_1024.affine   525312      -        [16, 1024]          float32 \n",
            "synthesis.L7_36_1024          1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L8_36_1024.affine   525312      -        [16, 1024]          float32 \n",
            "synthesis.L8_36_1024          1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L9_36_1024.affine   525312      -        [16, 1024]          float32 \n",
            "synthesis.L9_36_1024          1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L10_36_1024.affine  525312      -        [16, 1024]          float32 \n",
            "synthesis.L10_36_1024         1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L11_36_1024.affine  525312      -        [16, 1024]          float32 \n",
            "synthesis.L11_36_1024         1049600     157      [16, 1024, 36, 36]  float16 \n",
            "synthesis.L12_36_1024.affine  525312      -        [16, 1024]          float32 \n",
            "synthesis.L12_36_1024         1049600     25       [16, 1024, 36, 36]  float16 \n",
            "synthesis.L13_16_1024.affine  525312      -        [16, 1024]          float32 \n",
            "synthesis.L13_16_1024         1049600     25       [16, 1024, 16, 16]  float16 \n",
            "synthesis.L14_16_1.affine     525312      -        [16, 1024]          float32 \n",
            "synthesis.L14_16_1            1025        1        [16, 1, 16, 16]     float16 \n",
            "synthesis                     -           -        [16, 1, 16, 16]     float32 \n",
            "---                           ---         ---      ---                 ---     \n",
            "Total                         24151045    5528     -                   -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape       Datatype\n",
            "---            ---         ---      ---                ---     \n",
            "b16.fromrgb    1024        16       [16, 512, 16, 16]  float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]    float16 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]  float16 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]    float16 \n",
            "b16            -           16       [16, 512, 8, 8]    float16 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]    float16 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]    float16 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]    float16 \n",
            "b8             -           16       [16, 512, 4, 4]    float16 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]    float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]    float32 \n",
            "b4.fc          4194816     -        [16, 512]          float32 \n",
            "b4.out         513         -        [16, 1]            float32 \n",
            "---            ---         ---      ---                ---     \n",
            "Total          16524289    160      -                  -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYFbibJofhM7"
      },
      "id": "mYFbibJofhM7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iZuhM7_mfhRD"
      },
      "id": "iZuhM7_mfhRD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWrV4S5PfhWF"
      },
      "id": "wWrV4S5PfhWF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vy_bL4xDfhZ2"
      },
      "id": "Vy_bL4xDfhZ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o3jSe4offhdu"
      },
      "id": "o3jSe4offhdu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rGX23yPGfhh2"
      },
      "id": "rGX23yPGfhh2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ee711f7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ee711f7",
        "outputId": "0e4601ca-041e-4510-8d91-95d0d305b015",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r",
            "  0% 0/5842 [00:00<?, ?it/s]\r",
            "  0% 0/5842 [00:00<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Style_GAN_3/dataset_tool.py\", line 456, in <module>\n",
            "    convert_dataset() # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/decorators.py\", line 33, in new_func\n",
            "    return f(get_current_context(), *args, **kwargs)\n",
            "  File \"/content/drive/MyDrive/Style_GAN_3/dataset_tool.py\", line 412, in convert_dataset\n",
            "    img = transform_image(image['img'])\n",
            "  File \"/content/drive/MyDrive/Style_GAN_3/dataset_tool.py\", line 235, in center_crop\n",
            "    img = PIL.Image.fromarray(img, 'RGB')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3103, in fromarray\n",
            "    return frombuffer(mode, size, obj, \"raw\", rawmode, 0, 1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 3027, in frombuffer\n",
            "    return frombytes(mode, size, data, decoder_name, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 2969, in frombytes\n",
            "    im.frombytes(data, decoder_name, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/PIL/Image.py\", line 830, in frombytes\n",
            "    raise ValueError(msg)\n",
            "ValueError: not enough image data\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/Style_GAN_3/dataset_tool.py --source=/content/drive/MyDrive/MNIST/four_img.zip --dest=/content/drive/MyDrive/MNIST/four_new_img.zip --transform=center-crop --resolution=28x28\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2b0b775",
      "metadata": {
        "id": "e2b0b775",
        "outputId": "643036cf-e355-40d3-c6ad-ffa6e4bb0a7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|█████████████████████████████████████| 5842/5842 [00:02<00:00, 2044.61it/s]\n"
          ]
        }
      ],
      "source": [
        "!python stylegan3-main/dataset_tool.py --source=four_img.zip --dest=four_new_img.zip --transform=center-crop --resolution=16x16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0020c699",
      "metadata": {
        "id": "0020c699"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "py39",
      "language": "python",
      "name": "py39"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}